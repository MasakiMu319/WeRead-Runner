# main.py ä¸»é€»è¾‘ï¼šåŒ…æ‹¬å­—æ®µæ‹¼æ¥ã€æ¨¡æ‹Ÿè¯·æ±‚
import re
import os
import math
import json
import time
import random
import logging
import hashlib
import requests
import urllib.parse
from push import push
from config import data, headers, cookies, READ_NUM, PUSH_METHOD, book

# é…ç½®æ—¥å¿—æ ¼å¼
logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)-8s - %(message)s"
)

# åŠ å¯†ç›åŠå…¶å®ƒé»˜è®¤å€¼
KEY = "3c5c8717f3daf09iop3423zafeqoi"
COOKIE_DATA = {"rq": "%2Fweb%2Fbook%2FgetProgress", "ql": False}
READ_URL = "https://weread.qq.com/web/book/read"
PROGRESS_URL = "https://weread.qq.com/web/book/getProgress"
READER_URL = "https://weread.qq.com/web/reader"
RENEW_URL = "https://weread.qq.com/web/login/renewal"
FIX_SYNCKEY_URL = "https://weread.qq.com/web/book/chapterInfos"
READ_MIN_PER_SUCCESS = 0.5
RT_SECONDS = 30
SLEEP_MIN_SECONDS = RT_SECONDS + 1
SLEEP_MAX_SECONDS = RT_SECONDS + 15
SESSION_MINUTES_MIN = 20
SESSION_MINUTES_MAX = 40
REST_MINUTES_MIN = 3
REST_MINUTES_MAX = 8
PROGRESS_INTERVAL_MIN = 10
PROGRESS_INTERVAL_READS = int(PROGRESS_INTERVAL_MIN / READ_MIN_PER_SUCCESS)
VALID_PUSH_METHODS = {"pushplus", "telegram", "wxpusher", "serverchan"}


def encode_weread_id(value):
    """å¾®ä¿¡è¯»ä¹¦çš„ ID ç¼–ç ï¼ˆæ¥è‡ªå‰ç«¯é€»è¾‘ï¼‰"""
    if isinstance(value, int):
        value = str(value)
    if not isinstance(value, str):
        return value
    md5_hex = hashlib.md5(value.encode()).hexdigest()
    prefix = md5_hex[:3]
    if value.isdigit():
        pieces = []
        for i in range(0, len(value), 9):
            chunk = value[i : i + 9]
            pieces.append(format(int(chunk), "x"))
        flag = "3"
    else:
        pieces = ["".join(format(ord(ch), "x") for ch in value)]
        flag = "4"
    out = prefix + flag
    out += "2" + md5_hex[-2:]
    for idx, item in enumerate(pieces):
        length_hex = format(len(item), "x")
        if len(length_hex) == 1:
            length_hex = "0" + length_hex
        out += length_hex + item
        if idx < len(pieces) - 1:
            out += "g"
    if len(out) < 0x14:
        out += md5_hex[: 0x14 - len(out)]
    out += hashlib.md5(out.encode()).hexdigest()[:3]
    return out


def encode_data(data):
    """æ•°æ®ç¼–ç """
    return "&".join(
        f"{k}={urllib.parse.quote(str(data[k]), safe='')}" for k in sorted(data.keys())
    )


def cal_hash(input_string):
    """è®¡ç®—å“ˆå¸Œå€¼"""
    _7032f5 = 0x15051505
    _cc1055 = _7032f5
    length = len(input_string)
    _19094e = length - 1

    while _19094e > 0:
        _7032f5 = 0x7FFFFFFF & (
            _7032f5 ^ ord(input_string[_19094e]) << (length - _19094e) % 30
        )
        _cc1055 = 0x7FFFFFFF & (
            _cc1055 ^ ord(input_string[_19094e - 1]) << _19094e % 30
        )
        _19094e -= 2

    return hex(_7032f5 + _cc1055)[2:].lower()


def format_minutes(value):
    """æ ¼å¼åŒ–åˆ†é’Ÿæ•°ï¼Œé¿å… 10.0 è¿™ç§æ˜¾ç¤º"""
    if value == int(value):
        return str(int(value))
    return f"{value:.1f}"


def extract_safe_info(res_data):
    """æå–å®‰å…¨å­—æ®µç”¨äºå¤±è´¥åŸå› æè¿°"""
    if isinstance(res_data, dict):
        keys = ("errcode", "errmsg", "code", "message", "succ")
        return {k: res_data.get(k) for k in keys if k in res_data}
    return None


def safe_push(content, method):
    """å®‰å…¨æ¨é€ï¼šé¿å…å› æ¨é€é…ç½®é”™è¯¯å¯¼è‡´ä¸»æµç¨‹å´©æºƒ"""
    if method in (None, ""):
        logging.info("â„¹ï¸ PUSH_METHOD ä¸ºç©ºï¼Œè·³è¿‡æ¨é€ã€‚")
    return False


def get_start_delay_seconds():
    """æ ¹æ®ç¯å¢ƒå˜é‡è·å–å¯åŠ¨å»¶è¿Ÿï¼ˆç§’ï¼‰"""
    min_raw = os.getenv("WXREAD_START_DELAY_MIN")
    max_raw = os.getenv("WXREAD_START_DELAY_MAX")
    if not min_raw and not max_raw:
        return 0
    try:
        min_val = int(min_raw) if min_raw is not None else 0
    except ValueError:
        min_val = 0
    try:
        max_val = int(max_raw) if max_raw is not None else 0
    except ValueError:
        max_val = 0
    if min_val < 0:
        min_val = 0
    if max_val < 0:
        max_val = 0
    if max_val < min_val:
        min_val, max_val = max_val, min_val
    if max_val == 0 and min_val == 0:
        return 0
    return random.randint(min_val, max_val)
    method_norm = method.lower() if isinstance(method, str) else method
    if method_norm not in VALID_PUSH_METHODS:
        logging.warning("âš ï¸ PUSH_METHOD æ— æ•ˆ(%s)ï¼Œè·³è¿‡æ¨é€ã€‚", method)
        return False
    try:
        push(content, method_norm)
        return True
    except Exception as exc:
        logging.error("âŒ æ¨é€å¤±è´¥: %s", exc)
        return False


def extract_balanced_json(text, start_index):
    """æå–ä»æŒ‡å®šä½ç½®å¼€å§‹çš„ JSON å¯¹è±¡å­—ç¬¦ä¸²"""
    depth = 0
    in_string = False
    escape = False
    for i in range(start_index, len(text)):
        ch = text[i]
        if in_string:
            if escape:
                escape = False
            elif ch == "\\":
                escape = True
            elif ch == '"':
                in_string = False
        else:
            if ch == '"':
                in_string = True
            elif ch == "{":
                depth += 1
            elif ch == "}":
                depth -= 1
                if depth == 0:
                    return text[start_index : i + 1]
    return None


def extract_json_after_marker(text, marker):
    """ä»ç±»ä¼¼ window.__INITIAL_STATE__=... ä¸­æå– JSON å¯¹è±¡"""
    idx = text.find(marker)
    if idx == -1:
        return None
    brace_start = text.find("{", idx)
    if brace_start == -1:
        return None
    blob = extract_balanced_json(text, brace_start)
    if not blob:
        return None
    try:
        return json.loads(blob)
    except ValueError:
        return None


def extract_json_after_key(text, key):
    """ä» key: { ... } ä¸­æå– JSON å¯¹è±¡"""
    idx = text.find(key)
    if idx == -1:
        return None
    colon = text.find(":", idx)
    if colon == -1:
        return None
    brace_start = text.find("{", colon)
    if brace_start == -1:
        return None
    blob = extract_balanced_json(text, brace_start)
    if not blob:
        return None
    try:
        return json.loads(blob)
    except ValueError:
        return None


def find_key_recursive(obj, target_key):
    if isinstance(obj, dict):
        if target_key in obj:
            return obj[target_key]
        for value in obj.values():
            found = find_key_recursive(value, target_key)
            if found is not None:
                return found
    elif isinstance(obj, list):
        for item in obj:
            found = find_key_recursive(item, target_key)
            if found is not None:
                return found
    return None


def extract_initial_state(html):
    for marker in (
        "window.__INITIAL_STATE__",
        "__INITIAL_STATE__",
        "window.__NUXT__",
        "__NUXT__",
    ):
        state_obj = extract_json_after_marker(html, marker)
        if state_obj:
            return state_obj
    return None


def collect_readers(state_obj):
    readers = []

    def walk(obj):
        if isinstance(obj, dict):
            if "reader" in obj and isinstance(obj["reader"], dict):
                readers.append(obj["reader"])
            for value in obj.values():
                walk(value)
        elif isinstance(obj, list):
            for item in obj:
                walk(item)

    walk(state_obj)
    return readers


def get_reader_info(read_book_id):
    """è§£æ reader é¡µé¢ï¼Œè·å– progress çš„ bookId"""
    if not read_book_id:
        logging.error("âŒ æœªæŒ‡å®š reader bookIdã€‚")
        return None
    url = f"{READER_URL}/{read_book_id}"
    try:
        response = requests.get(url, headers=headers, cookies=cookies)
    except Exception as exc:
        logging.error("âŒ è·å– reader é¡µé¢å¤±è´¥: %s", exc)
        return None
    resp_cookie_dict = response.cookies.get_dict()
    if resp_cookie_dict:
        cookies.update(resp_cookie_dict)
    html = response.text or ""
    reader_obj = None
    readers = []
    state_obj = extract_initial_state(html)
    if state_obj:
        readers = collect_readers(state_obj)
        for item in readers:
            if (
                isinstance(item, dict)
                and item.get("chapterInfos")
                and (item.get("bookId") or item.get("book", {}).get("bookId"))
            ):
                reader_obj = item
                break
        if not reader_obj and readers:
            reader_obj = readers[0]
    if not reader_obj:
        reader_obj = extract_json_after_key(html, '"reader"')
    progress_book_id = None
    if isinstance(reader_obj, dict):
        progress_book_id = reader_obj.get("bookId") or reader_obj.get("book", {}).get(
            "bookId"
        )
    if not progress_book_id:
        match = re.search(r'"bookId"\s*:\s*"(\d+)"', html)
        if match:
            progress_book_id = match.group(1)
    if not progress_book_id:
        logging.error("âŒ reader é¡µé¢æœªè§£æåˆ° progress bookIdã€‚")
        book_id_candidates = re.findall(r'"bookId"\s*:\s*"(\d+)"', html)[:5]
        logging.error(
            "ğŸ” reader è°ƒè¯•: url=%s status=%s len=%s has_state=%s readers=%s bookIdå€™é€‰=%s",
            url,
            response.status_code,
            len(html),
            True if state_obj else False,
            len(readers),
            book_id_candidates if book_id_candidates else None,
        )
        return None
    return {"progress_book_id": str(progress_book_id)}


def get_progress(book_id):
    """è·å–æŒ‡å®šä¹¦ç±çš„é˜…è¯»è¿›åº¦"""
    if not book_id:
        logging.error("âŒ æœªæŒ‡å®š bookIdï¼Œæ— æ³•è·å–é˜…è¯»è¿›åº¦ã€‚")
        return None
    try:
        response = requests.get(
            PROGRESS_URL, headers=headers, cookies=cookies, params={"bookId": book_id}
        )
        res_data = response.json()
    except Exception as exc:
        logging.error("âŒ è·å–é˜…è¯»è¿›åº¦å¤±è´¥: %s", exc)
        return None
    if not isinstance(res_data, dict):
        logging.error("âŒ è·å–é˜…è¯»è¿›åº¦è¿”å›éå¯¹è±¡ã€‚")
        return None
    safe_info = extract_safe_info(res_data)
    if safe_info:
        logging.info("ğŸ” è¿›åº¦å“åº”: %s", safe_info)
    if "book" not in res_data:
        logging.error("âŒ è·å–é˜…è¯»è¿›åº¦ç¼ºå°‘ book å­—æ®µã€‚")
        return None
    return res_data


def get_chapter_infos(book_id):
    """è·å–ç« èŠ‚ä¿¡æ¯åˆ—è¡¨"""
    if not book_id:
        logging.error("âŒ æœªæŒ‡å®š bookIdï¼Œæ— æ³•è·å–ç« èŠ‚ä¿¡æ¯ã€‚")
        return None
    response = requests.post(
        FIX_SYNCKEY_URL,
        headers=headers,
        cookies=cookies,
        data=json.dumps({"bookIds": [str(book_id)]}, separators=(",", ":")),
    )
    try:
        res_data = response.json()
    except ValueError:
        logging.error("âŒ ç« èŠ‚ä¿¡æ¯è¿”å›é JSONã€‚")
        return None
    if not isinstance(res_data, dict):
        logging.error("âŒ ç« èŠ‚ä¿¡æ¯è¿”å›éå¯¹è±¡ã€‚")
        return None
    items = res_data.get("data") or []
    if not items:
        logging.error("âŒ ç« èŠ‚ä¿¡æ¯ä¸ºç©ºã€‚")
        return None
    target = next(
        (item for item in items if str(item.get("bookId")) == str(book_id)), items[0]
    )
    book_meta = target.get("book") or {}
    updated = target.get("updated") or []
    chapters = []
    for item in updated:
        idx = item.get("chapterIdx")
        uid = item.get("chapterUid")
        if idx is None or uid is None:
            continue
        chapters.append(
            {
                "idx": int(idx),
                "uid": uid,
                "word_count": int(item.get("wordCount") or 0),
                "title": item.get("title"),
            }
        )
    chapters.sort(key=lambda x: x["idx"])
    if not chapters:
        logging.error("âŒ ç« èŠ‚ä¿¡æ¯è§£æä¸ºç©ºã€‚")
        return None
    return chapters, book_meta


def calc_read_step(interval_sec, word_count):
    """æ ¹æ®æ—¶é—´é—´éš”ä¼°ç®—é˜…è¯»æ¨è¿›é‡"""
    interval = max(1, int(interval_sec))
    speed = random.uniform(3.0, 6.0)
    step = max(50, int(interval * speed))
    if word_count and word_count > 0:
        max_step = max(200, int(word_count * 0.05))
        step = min(step, max_step)
    return step


def advance_chapter_pos(current_pos, readable_positions):
    """æ¨è¿›åˆ°ä¸‹ä¸€ä¸ªå¯è¯»ç« èŠ‚"""
    if not readable_positions:
        return current_pos
    for pos in readable_positions:
        if pos > current_pos:
            return pos
    return readable_positions[0]


def build_readable_positions(chapters):
    """ç­›é€‰å¯é˜…è¯»ç« èŠ‚ç´¢å¼•"""
    readable = []
    for i, ch in enumerate(chapters):
        if ch.get("word_count", 0) > 50:
            readable.append(i)
    if readable:
        return readable
    return [i for i, ch in enumerate(chapters)]


def pick_random_chapter(chapters, readable_positions):
    """éšæœºé€‰æ‹©ç« èŠ‚å¹¶è¿”å›ä½ç½®ã€åç§»ã€æ‘˜è¦"""
    pos = random.choice(readable_positions) if readable_positions else 0
    chapter = chapters[pos]
    word_count = chapter.get("word_count", 0)
    if word_count and word_count > 0:
        offset = random.randint(10, min(80, max(10, word_count // 50)))
    else:
        offset = 0
    return pos, offset, chapter.get("title")


def get_wr_skey():
    """åˆ·æ–°cookieå¯†é’¥"""
    response = requests.post(
        RENEW_URL,
        headers=headers,
        cookies=cookies,
        data=json.dumps(COOKIE_DATA, separators=(",", ":")),
    )
    resp_cookie_dict = response.cookies.get_dict()
    if resp_cookie_dict:
        cookies.update(resp_cookie_dict)
    wr_skey = resp_cookie_dict.get("wr_skey") if resp_cookie_dict else response.cookies.get("wr_skey")
    if not wr_skey:
        set_cookie = response.headers.get("Set-Cookie", "")
        match = re.search(r"wr_skey=([^;]+)", set_cookie)
        if match:
            wr_skey = match.group(1)
            cookies["wr_skey"] = wr_skey
    logging.info(
        "ğŸ” ç»­æœŸå“åº”: status=%s, set_cookie=%s, wr_skey=%s",
        response.status_code,
        "present" if "Set-Cookie" in response.headers else "missing",
        "found" if wr_skey else "missing",
    )
    try:
        resp_json = response.json()
    except ValueError:
        resp_json = None
    if isinstance(resp_json, dict):
        safe_keys = ("errcode", "errmsg", "succ", "code", "message")
        safe_info = {k: resp_json.get(k) for k in safe_keys if k in resp_json}
        if safe_info:
            logging.info("ğŸ” ç»­æœŸJSON: %s", safe_info)
    return wr_skey if wr_skey else None


def fix_no_synckey(book_id):
    if not book_id:
        return
    requests.post(
        FIX_SYNCKEY_URL,
        headers=headers,
        cookies=cookies,
        data=json.dumps({"bookIds": [str(book_id)]}, separators=(",", ":")),
    )


def refresh_cookie():
    logging.info(f"ğŸª åˆ·æ–°cookie")
    new_skey = get_wr_skey()
    if new_skey:
        cookies["wr_skey"] = new_skey
        logging.info(f"âœ… å¯†é’¥åˆ·æ–°æˆåŠŸï¼Œæ–°å¯†é’¥ï¼š{new_skey}")
        logging.info(f"ğŸ”„ é‡æ–°æœ¬æ¬¡é˜…è¯»ã€‚")
        return True
    else:
        ERROR_CODE = "âŒ æ— æ³•è·å–æ–°å¯†é’¥æˆ–è€…WXREAD_CURL_BASHé…ç½®æœ‰è¯¯ï¼Œç»§ç»­å°è¯•ã€‚"
        logging.error(ERROR_CODE)
        logging.warning("âš ï¸ åˆ·æ–°å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨æ—§ cookie å°è¯•ã€‚")
        return False


start_delay_seconds = get_start_delay_seconds()
if start_delay_seconds > 0:
    logging.info("â³ å»¶è¿Ÿå¯åŠ¨ï¼š%s ç§’", start_delay_seconds)
    safe_push(
        f"â³ ä»»åŠ¡å»¶è¿Ÿå¯åŠ¨\n"
        f"é¢„è®¡å»¶è¿Ÿï¼š{start_delay_seconds // 60}åˆ†{start_delay_seconds % 60}ç§’",
        PUSH_METHOD,
    )
    time.sleep(start_delay_seconds)

refresh_cookie()
index = 1
success_count = 0
stopped_reason = None
min_reads = max(READ_NUM, math.ceil(180 / READ_MIN_PER_SUCCESS))
max_reads = int(min_reads * 1.5)
target_reads = random.randint(min_reads, max_reads)
target_minutes = target_reads * READ_MIN_PER_SUCCESS
read_book_id = random.choice(book) if book else data.get("b")
progress_book_id = None
progress = None
app_id = data.get("appId")
current_idx = data.get("ci") or 1
current_offset = data.get("co") or 0
current_summary = data.get("sm") or ""
chapters = None
book_meta = {}
chapter_pos = 0
readable_positions = None
last_readable_pos = 0
session_minutes = 0.0
session_target_minutes = random.randint(SESSION_MINUTES_MIN, SESSION_MINUTES_MAX)
last_progress_push_ts = None
last_report_mono = None
logging.info(
    "â±ï¸ ä¸€å…±éœ€è¦é˜…è¯» %s æ¬¡ï¼ˆä¸‹é™=%sæ¬¡ï¼‰...",
    target_reads,
    READ_NUM,
)
if not read_book_id:
    stopped_reason = "æœªæ‰¾åˆ°å¯ç”¨çš„ bookIdã€‚"
else:
    reader_info = get_reader_info(read_book_id)
    if not reader_info:
        stopped_reason = "è¯»å– reader ä¿¡æ¯å¤±è´¥ã€‚"
    else:
        progress_book_id = reader_info["progress_book_id"]
        progress = get_progress(progress_book_id)
    if not stopped_reason and not progress:
        stopped_reason = "è·å–é˜…è¯»è¿›åº¦å¤±è´¥ã€‚"
    elif not stopped_reason:
        progress_book = progress.get("book") or {}
        app_id = progress_book.get("appId") or app_id
        if progress_book_id:
            read_book_id = encode_weread_id(progress_book_id)
        progress_idx = progress_book.get("chapterIdx")
        if progress_idx is not None:
            current_idx = progress_idx
        progress_offset = progress_book.get("chapterOffset")
        if progress_offset is not None:
            current_offset = progress_offset
        current_summary = progress_book.get("summary") or current_summary
        try:
            current_idx = int(current_idx)
        except (TypeError, ValueError):
            current_idx = 1
        try:
            current_offset = int(current_offset)
        except (TypeError, ValueError):
            current_offset = 0
        chapters_result = get_chapter_infos(progress_book_id)
        if not chapters_result:
            stopped_reason = "è·å–ç« èŠ‚ä¿¡æ¯å¤±è´¥ã€‚"
        else:
            chapters, book_meta = chapters_result
            readable_positions = build_readable_positions(chapters)
            if not readable_positions:
                stopped_reason = "æ— å¯è¯»ç« èŠ‚ï¼Œæ— æ³•ç»§ç»­ã€‚"
                readable_positions = None
            else:
                last_readable_pos = readable_positions[-1]
            if stopped_reason:
                pass
            else:
                chapter_pos = next(
                    (i for i, ch in enumerate(chapters) if ch["idx"] == int(current_idx)),
                    None,
                )
                if chapter_pos is None or chapter_pos not in readable_positions:
                    chapter_pos = readable_positions[0]
                    current_idx = chapters[chapter_pos]["idx"]
                current_word_count = chapters[chapter_pos].get("word_count", 0)
                if current_word_count and current_offset >= current_word_count:
                    current_offset = max(0, current_word_count - 1)
                if current_word_count <= 50:
                    chapter_pos = advance_chapter_pos(chapter_pos, readable_positions)
                    current_idx = chapters[chapter_pos]["idx"]
                chapter_title = chapters[chapter_pos].get("title")
                if chapter_title:
                    current_summary = chapter_title
                logging.info(
                    "ğŸ“š ä¹¦ç±=%s ç« èŠ‚æ•°=%s èµ·å§‹ç« èŠ‚=%s",
                    read_book_id,
                    len(chapters),
                    current_idx,
                )

if not stopped_reason:
    book_title = book_meta.get("title") if isinstance(book_meta, dict) else None
    book_author = book_meta.get("author") if isinstance(book_meta, dict) else None
    if book_title and book_author:
        book_line = f"ğŸ“š ä¹¦ç±ï¼š{book_title} - {book_author}"
    elif book_title:
        book_line = f"ğŸ“š ä¹¦ç±ï¼š{book_title}"
    elif progress_book_id:
        book_line = f"ğŸ“š ä¹¦ç±IDï¼š{progress_book_id}"
    else:
        book_line = None
    start_lines = [
        "ğŸš€ å¼€å§‹è‡ªåŠ¨é˜…è¯»",
        f"ğŸ¯ ç›®æ ‡æ¬¡æ•°ï¼š{target_reads} æ¬¡",
        f"â±ï¸ ç›®æ ‡æ—¶é•¿ï¼š{format_minutes(target_minutes)} åˆ†é’Ÿ",
    ]
    if book_line:
        start_lines.insert(1, book_line)
    safe_push(
        "\n".join(start_lines),
        PUSH_METHOD,
    )

    while index <= target_reads:
        data.pop("s", None)
        current_chapter = chapters[chapter_pos]
        current_idx = current_chapter["idx"]
        current_uid = current_chapter.get("uid")
        current_word_count = current_chapter.get("word_count", 0)
        chapter_title = current_chapter.get("title")
        if chapter_title:
            current_summary = chapter_title
        chapter_id = encode_weread_id(current_uid) if current_uid is not None else None
        if not chapter_id:
            stopped_reason = f"æ— æ³•åŒ¹é…ç« èŠ‚ID(chapterUid={current_uid})ï¼Œå·²åœæ­¢ã€‚"
            break
        data["c"] = chapter_id
        data["appId"] = app_id
        data["b"] = read_book_id
        data["ci"] = int(current_idx)
        data["co"] = int(current_offset)
        if current_summary:
            data["sm"] = current_summary
        data["pr"] = max(0, int(current_offset // 1000))

        thisTime = int(time.time())
        data["ct"] = thisTime
        data["rt"] = RT_SECONDS
        data["ts"] = int(thisTime * 1000) + random.randint(0, 1000)
        data["rn"] = random.randint(0, 1000)
        data["sg"] = hashlib.sha256(f"{data['ts']}{data['rn']}{KEY}".encode()).hexdigest()
        data["s"] = cal_hash(encode_data(data))

        logging.info(f"â±ï¸ å°è¯•ç¬¬ {index} æ¬¡é˜…è¯»...")
        logging.info(f"ğŸ“• data: {data}")
        response = requests.post(
            READ_URL,
            headers=headers,
            cookies=cookies,
            data=json.dumps(data, separators=(",", ":")),
        )
        try:
            resData = response.json()
        except ValueError:
            resData = {"message": "non-json response", "status": response.status_code}
        logging.info(f"ğŸ“• response: {resData}")

        if "succ" in resData:
            if "synckey" in resData:
                interval = data["rt"]
                success_count += 1
                index += 1

                step = calc_read_step(interval, current_word_count)
                current_offset += step
                if current_word_count <= 0:
                    chapter_pos = advance_chapter_pos(chapter_pos, readable_positions)
                    next_chapter = chapters[chapter_pos]
                    current_idx = next_chapter["idx"]
                    current_offset = 0
                    if next_chapter.get("title"):
                        current_summary = next_chapter["title"]
                elif current_offset >= current_word_count:
                    if chapter_pos == last_readable_pos:
                        chapter_pos, current_offset, new_summary = pick_random_chapter(
                            chapters, readable_positions
                        )
                        current_idx = chapters[chapter_pos]["idx"]
                        if new_summary:
                            current_summary = new_summary
                    else:
                        chapter_pos = advance_chapter_pos(
                            chapter_pos, readable_positions
                        )
                        next_chapter = chapters[chapter_pos]
                        current_idx = next_chapter["idx"]
                        next_word_count = next_chapter.get("word_count", 0)
                        if next_word_count and next_word_count > 0:
                            current_offset = random.randint(
                                10, min(80, max(10, next_word_count // 50))
                            )
                        else:
                            current_offset = 0
                        if next_chapter.get("title"):
                            current_summary = next_chapter["title"]

                session_minutes += READ_MIN_PER_SUCCESS
                if session_minutes >= session_target_minutes:
                    rest_minutes = random.randint(REST_MINUTES_MIN, REST_MINUTES_MAX)
                    logging.info(
                        "ğŸ˜´ è¿ç»­é˜…è¯» %s åˆ†é’Ÿï¼Œä¼‘æ¯ %s åˆ†é’Ÿ",
                        format_minutes(session_minutes),
                        rest_minutes,
                    )
                    safe_push(
                        "ğŸ˜´ è¿›å…¥ä¼‘æ¯\n"
                        f"å·²è¿ç»­é˜…è¯»ï¼š{format_minutes(session_minutes)} åˆ†é’Ÿ\n"
                        f"é¢„è®¡ä¼‘æ¯ï¼š{rest_minutes} åˆ†é’Ÿ",
                        PUSH_METHOD,
                    )
                    time.sleep(rest_minutes * 60)
                    session_minutes = 0.0
                    session_target_minutes = random.randint(
                        SESSION_MINUTES_MIN, SESSION_MINUTES_MAX
                    )
                    safe_push(
                        "âœ… ä¼‘æ¯ç»“æŸï¼Œç»§ç»­é˜…è¯»\n"
                        f"ä¸‹ä¸€è½®ç›®æ ‡ï¼š{session_target_minutes} åˆ†é’Ÿ",
                        PUSH_METHOD,
                    )
                time.sleep(random.randint(SLEEP_MIN_SECONDS, SLEEP_MAX_SECONDS))
                done_minutes = success_count * READ_MIN_PER_SUCCESS
                now_mono = time.monotonic()
                if last_report_mono is None:
                    report_gap = "é¦–æ¬¡ä¸ŠæŠ¥"
                else:
                    gap_seconds = int(now_mono - last_report_mono)
                    report_gap = f"{gap_seconds}ç§’"
                last_report_mono = now_mono
                logging.info(
                    "âœ… é˜…è¯»æˆåŠŸï¼Œé˜…è¯»è¿›åº¦ï¼š%s åˆ†é’Ÿï¼ˆè·ä¸Šæ¬¡ä¸ŠæŠ¥ï¼š%sï¼‰",
                    format_minutes(done_minutes),
                    report_gap,
                )
                if success_count % PROGRESS_INTERVAL_READS == 0:
                    now_ts = int(time.time())
                    if last_progress_push_ts is None:
                        gap_text = "é¦–æ¬¡ä¸ŠæŠ¥"
                    else:
                        gap_seconds = now_ts - last_progress_push_ts
                        gap_text = f"{gap_seconds // 60}åˆ†{gap_seconds % 60}ç§’"
                    safe_push(
                        f"ğŸ“ˆ é˜…è¯»è¿›åº¦ï¼š{format_minutes(done_minutes)} åˆ†é’Ÿ / "
                        f"{format_minutes(target_minutes)} åˆ†é’Ÿ\n"
                        f"â±ï¸ è·ä¸Šæ¬¡ä¸ŠæŠ¥ï¼š{gap_text}",
                        PUSH_METHOD,
                    )
                    last_progress_push_ts = now_ts
            else:
                logging.warning("âŒ æ— synckey, å°è¯•ä¿®å¤...")
                fix_no_synckey(progress_book_id)
        else:
            logging.warning("âŒ é˜…è¯»å¤±è´¥ï¼Œå°è¯•åˆ·æ–°cookie...")
            refresh_ok = refresh_cookie()
            if not refresh_ok:
                safe_info = extract_safe_info(resData) or {}
                reason_parts = ["é˜…è¯»æ¥å£å¤±è´¥ä¸”åˆ·æ–°cookieå¤±è´¥ï¼Œå·²åœæ­¢ã€‚"]
                if safe_info:
                    reason_parts.append(f"åŸå› ï¼š{safe_info}")
                stopped_reason = " ".join(reason_parts)
                break

total_minutes = success_count * READ_MIN_PER_SUCCESS
if stopped_reason:
    logging.error("ğŸ›‘ é˜…è¯»å·²åœæ­¢ï¼š%s", stopped_reason)
    safe_push(
        f"ğŸ›‘ å¾®ä¿¡è¯»ä¹¦è‡ªåŠ¨é˜…è¯»å·²åœæ­¢\n"
        f"{stopped_reason}\n"
        f"â±ï¸ å·²å®Œæˆï¼š{format_minutes(total_minutes)} åˆ†é’Ÿ",
        PUSH_METHOD,
    )
else:
    logging.info("ğŸ‰ é˜…è¯»è„šæœ¬å·²å®Œæˆï¼")
    safe_push(
        f"ğŸ‰ å¾®ä¿¡è¯»ä¹¦è‡ªåŠ¨é˜…è¯»å®Œæˆï¼\nâ±ï¸ é˜…è¯»æ—¶é•¿ï¼š{format_minutes(total_minutes)} åˆ†é’Ÿã€‚",
        PUSH_METHOD,
    )
